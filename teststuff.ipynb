{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eib5J7TxG5kY",
        "outputId": "30f70b4a-f4fa-4a13-b716-932370d5d6b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/295.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies.\n",
        "!rm -r sample_data\n",
        "!pip install -qq --upgrade transformers compel accelerate git+https://github.com/huggingface/diffusers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL7u2wgpHilQ"
      },
      "outputs": [],
      "source": [
        "# Set the details for your model here:\n",
        "import torch\n",
        "\n",
        "from diffusers import AutoencoderKL, StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "\n",
        "use_refiner = True\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "base = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        ")\n",
        "_ = base.to(\"cuda\")\n",
        "\n",
        "if use_refiner:\n",
        "  refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "      vae=vae,\n",
        "      text_encoder_2=base.text_encoder_2,\n",
        "      torch_dtype=torch.float16,\n",
        "      variant=\"fp16\",\n",
        "      use_safetensors=True,\n",
        "  )\n",
        "  _ = refiner.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "7RqOhMJwmHcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_prompt = \"bokeh, painting, artwork, blocky, blur, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, blurry, assymetrical, unrealistic, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands\"\n",
        "prompt=\"Photograph of woman in red dress in a luxury garden surrounded with blue, yellow, purple and flowers in many colors, high class, award-winning photography, Portra 400, full format\"\n",
        "prompt += \"blue sky, intricate details even to the smallest particle, extreme detail of the environment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece, 8k\"\n",
        "\n",
        "num_inference_steps = 30\n",
        "guidance_scale = 10\n",
        "\n",
        "def soft_clamp_tensor(input_tensor, threshold=3.5, boundary=4):\n",
        "    if max(abs(input_tensor.max()), abs(input_tensor.min())) < 4:\n",
        "        return input_tensor\n",
        "    channel_dim = 1\n",
        "\n",
        "    max_vals = input_tensor.max(channel_dim, keepdim=True)[0]\n",
        "    max_replace = ((input_tensor - threshold) / (max_vals - threshold)) * (boundary - threshold) + threshold\n",
        "    over_mask = (input_tensor > threshold)\n",
        "\n",
        "    min_vals = input_tensor.min(channel_dim, keepdim=True)[0]\n",
        "    min_replace = ((input_tensor + threshold) / (min_vals + threshold)) * (-boundary + threshold) - threshold\n",
        "    under_mask = (input_tensor < -threshold)\n",
        "\n",
        "    return torch.where(over_mask, max_replace, torch.where(under_mask, min_replace, input_tensor))\n",
        "\n",
        "def callback(pipe, step_index, timestep, cbk):\n",
        "    print(cbk[\"latents\"].max(), cbk[\"latents\"].min(), cbk[\"latents\"].mean())\n",
        "    return cbk\n",
        "\n",
        "base_seed = 2222\n",
        "base_generator = torch.Generator()\n",
        "base_generator.manual_seed(base_seed)\n",
        "if use_refiner:\n",
        "  refiner_generator = torch.Generator()\n",
        "  refiner_generator.manual_seed(base_seed ^ 0xffffffff)\n",
        "\n",
        "image = base(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale = guidance_scale, generator=base_generator, denoising_end=0.8 if use_refiner else 1.0, output_type=\"latent\" if use_refiner else \"pil\").images\n",
        "if use_refiner:\n",
        "  image = refiner(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, generator=refiner_generator, denoising_start=0.8, image=image).images\n",
        "display(image[0])"
      ],
      "metadata": {
        "id": "9rhH5n5TOnX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import os\n",
        "import time\n",
        "import diffusers\n",
        "from diffusers import PNDMScheduler\n",
        "\n",
        "prompt=\"Photograph of a beautiful woman standing in a lush garden\"\n",
        "negative_prompt = \"bokeh, painting, artwork, blocky, blur, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, blurry, assymetrical, unrealistic, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands\"\n",
        "prompt += \"intricate details even to the smallest particle, extreme detail of the environment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece, 8k\"\n",
        "\n",
        "for use_karras_sigmas in [True]:\n",
        "    for scheduler in base.scheduler.compatibles:\n",
        "        scheduler_name = scheduler.__name__\n",
        "        if scheduler_name in (\"PNDMScheduler\", \"KDPM2AncestralDiscreteScheduler\"):\n",
        "            ske = scheduler.from_config(base.scheduler.config, use_karras_sigmas=use_karras_sigmas)\n",
        "            base.scheduler = ske\n",
        "            for num_inference_steps in range(5, 36, 5):\n",
        "                print(\"Generating with\", scheduler_name)\n",
        "                start_time = time.time()\n",
        "                latents = base(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, denoising_end=0.8, output_type=\"latent\").images\n",
        "                image = refiner(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, denoising_start=0.8, image=latents).images[0]\n",
        "                folder_path = f\"/content/drive/MyDrive/schedulers/{'k' if use_karras_sigmas else ''}{num_inference_steps}\"\n",
        "                os.makedirs(folder_path, exist_ok=True)\n",
        "                image.save(f\"{folder_path}/{str(round(float(time.time()-start_time),2)).replace('.', ',')}_{scheduler_name}.png\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bXSsr9d-hyF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r png_files.zip *.png\n",
        "!rm -r *.png"
      ],
      "metadata": {
        "id": "iPC0I6Aj0qpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}