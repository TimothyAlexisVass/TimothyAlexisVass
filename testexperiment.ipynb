{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eib5J7TxG5kY"
      },
      "outputs": [],
      "source": [
        "# Install dependencies.\n",
        "!rm -r sample_data\n",
        "!pip install -qq --upgrade transformers compel accelerate diffusers\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3qB9PG8zR4ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fL7u2wgpHilQ"
      },
      "outputs": [],
      "source": [
        "# Set the details for your model here:\n",
        "import torch\n",
        "\n",
        "from diffusers import AutoencoderKL, StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "\n",
        "use_refiner = True\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "base = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        "    add_watermarker=False\n",
        ").to(\"cuda\")\n",
        "\n",
        "if use_refiner:\n",
        "  refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "      vae=vae,\n",
        "      text_encoder_2=base.text_encoder_2,\n",
        "      torch_dtype=torch.float16,\n",
        "      variant=\"fp16\",\n",
        "      use_safetensors=True,\n",
        "      add_watermarker=False\n",
        "  ).to(\"cuda\")\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "7RqOhMJwmHcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_prompt = \"bokeh, painting, artwork, blocky, blur, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, blurry, assymetrical, unrealistic, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands\"\n",
        "prompt = \"close up Photograph of woman in red dress in a luxury garden surrounded with blue, yellow, purple and flowers in many colors, high class, award-winning photography, Portra 400, full format\"\n",
        "prompt = \"Cute girl with cool outfit, happily running on the beautiful flowery meadow, disney pixar, volumetric lighting\"\n",
        "prompt += \"intricate details, extreme detail of the environment, sharp portrait, well lit, interesting clothes,radial gradient fade directional particle lighting, subsurface scattering, ambient occlusion, neighborhood average tonal shading, bright, ultra realistic\"\n",
        "\n",
        "def clear_outliers(tensor, strength=20, method=\"mean\"):\n",
        "    axis = (2, 3)\n",
        "\n",
        "    mean = tensor.mean(axis, keepdim=True).expand_as(tensor)\n",
        "    std = tensor.std(axis, keepdim=True).expand_as(tensor)\n",
        "\n",
        "    z_score = 4.1-strength*0.025\n",
        "\n",
        "    if method==\"mean\":\n",
        "        return torch.where((tensor < mean - z_score * std) | (tensor > mean + z_score * std), mean, tensor)\n",
        "    elif method==\"threshold\":\n",
        "        outliers = torch.abs(tensor - mean) > z_score * std\n",
        "        shift = z_score * std[outliers]\n",
        "        tensor[outliers] = torch.where(tensor[outliers] > mean[outliers], mean[outliers] + shift, mean[outliers] - shift)\n",
        "    return tensor\n",
        "\n",
        "def maximize_tensor(tensor, strength):\n",
        "    initial_boundary = max(abs(tensor.min()), abs(tensor.max()))\n",
        "    new_boundary = initial_boundary + (4 - initial_boundary) * strength / 100\n",
        "\n",
        "    normalization_factor = new_boundary / initial_boundary\n",
        "\n",
        "    return tensor * normalization_factor\n",
        "\n",
        "def center_shift_tensor(tensor, channel_shift=1, full_shift=1, channels=[0, 1, 2, 3]):\n",
        "    for channel in channels:\n",
        "        tensor[0, channel] -= tensor[0, channel].mean() * channel_shift\n",
        "    return tensor - tensor.mean() * full_shift\n",
        "\n",
        "def callback(pipe, step_index, timestep, cbk):\n",
        "    boundary = max(abs(cbk[\"latents\"].min()), abs(cbk[\"latents\"].max()))\n",
        "    if step_index == 0:\n",
        "        cbk[\"latents\"] = center_shift_tensor(cbk[\"latents\"], channel_shift=0.01*shift_strength, full_shift=0.01*shift_strength)\n",
        "    elif timestep > 500:\n",
        "        cbk[\"latents\"] = center_shift_tensor(cbk[\"latents\"], channel_shift=0.008*shift_strength, full_shift=0.01*shift_strength)\n",
        "    if step_index < 5:\n",
        "      cbk[\"latents\"] = clear_outliers(cbk[\"latents\"], strength=clear_outliers_strength, method=clear_outliers_method)\n",
        "      cbk[\"latents\"] *= 1 + maximize_strength/11111\n",
        "    if timestep > 200 and timestep < 300:\n",
        "        cbk[\"latents\"] = center_shift_tensor(cbk[\"latents\"], channel_shift=0.004*shift_strength, full_shift=0.005*shift_strength, channels=[0, 1, 2])\n",
        "    if timestep == 1:\n",
        "        cbk[\"latents\"] = maximize_tensor(cbk[\"latents\"], strength=maximize_strength)\n",
        "    return cbk\n",
        "\n",
        "num_inference_steps = 30\n",
        "guidance_scale = 20\n",
        "maximize_strength = 0\n",
        "shift_strength = 0\n",
        "clear_outliers_strength = 0\n",
        "clear_outliers_method = \"threshold\"\n",
        "\n",
        "import os\n",
        "\n",
        "for maximize_strength in range(0, 101, 25):\n",
        "  for shift_strength in range(0, 101, 10):\n",
        "    for clear_outliers_strength in range(0, 101, 10):\n",
        "      file = f\"/content/drive/MyDrive/correction{maximize_strength}_{shift_strength}_{clear_outliers_strength}.png\"\n",
        "      if os.path.exists(file):\n",
        "        continue\n",
        "      print(clear_outliers_strength, shift_strength, maximize_strength)\n",
        "      base_seed = 3\n",
        "      base_generator = torch.Generator()\n",
        "      base_generator.manual_seed(base_seed)\n",
        "      if use_refiner:\n",
        "        refiner_generator = torch.Generator()\n",
        "        refiner_generator.manual_seed(base_seed ^ 0xffffffff)\n",
        "\n",
        "      image = base(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale = guidance_scale, callback_on_step_end=callback, callback_on_step_end_inputs=[\"latents\"], generator=base_generator, denoising_end=0.8 if use_refiner else 1.0, output_type=\"latent\" if use_refiner else \"pil\").images\n",
        "      if use_refiner:\n",
        "        image = refiner(prompt, negative_prompt=negative_prompt, num_inference_steps=int(num_inference_steps*1.5), callback_on_step_end=callback, callback_on_step_end_inputs=[\"latents\"], generator=refiner_generator, denoising_start=0.8, image=image).images\n",
        "      image[0].save(file)"
      ],
      "metadata": {
        "id": "9rhH5n5TOnX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import os\n",
        "import time\n",
        "import diffusers\n",
        "from diffusers import PNDMScheduler\n",
        "\n",
        "prompt=\"Photograph of a beautiful woman standing in a lush garden\"\n",
        "negative_prompt = \"bokeh, painting, artwork, blocky, blur, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, blurry, assymetrical, unrealistic, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands\"\n",
        "prompt += \"intricate details even to the smallest particle, extreme detail of the environment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece, 8k\"\n",
        "\n",
        "for use_karras_sigmas in [True]:\n",
        "    for scheduler in base.scheduler.compatibles:\n",
        "        scheduler_name = scheduler.__name__\n",
        "        if scheduler_name in (\"PNDMScheduler\", \"KDPM2AncestralDiscreteScheduler\"):\n",
        "            ske = scheduler.from_config(base.scheduler.config, use_karras_sigmas=use_karras_sigmas)\n",
        "            base.scheduler = ske\n",
        "            for num_inference_steps in range(5, 36, 5):\n",
        "                print(\"Generating with\", scheduler_name)\n",
        "                start_time = time.time()\n",
        "                latents = base(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, denoising_end=0.8, output_type=\"latent\").images\n",
        "                image = refiner(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, denoising_start=0.8, image=latents).images[0]\n",
        "                folder_path = f\"/content/drive/MyDrive/schedulers/{'k' if use_karras_sigmas else ''}{num_inference_steps}\"\n",
        "                os.makedirs(folder_path, exist_ok=True)\n",
        "                image.save(f\"{folder_path}/{str(round(float(time.time()-start_time),2)).replace('.', ',')}_{scheduler_name}.png\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bXSsr9d-hyF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r png_files.zip *.png\n",
        "!rm -r *.png"
      ],
      "metadata": {
        "id": "iPC0I6Aj0qpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}